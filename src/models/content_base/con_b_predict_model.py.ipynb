{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5a19010e-354d-429f-8ca7-5685e05cbf6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# import numpy as np\n",
    "\n",
    "\n",
    "# import joblib\n",
    "# import requests\n",
    "\n",
    "\n",
    "\n",
    "# FILTERD_BOOKS = r'C:\\Users\\gattu\\hybrid-book-recommendation-system\\models\\content base\\filtired_books_cb.pkl'\n",
    "# sim_matrix = r'C:\\Users\\gattu\\hybrid-book-recommendation-system\\data\\processed\\For content base\\similarity_matrix_cb.h5'\n",
    "\n",
    "# #  downcast data types\n",
    "# def downcast_dtypes(df):\n",
    "#     float_cols = [c for c in df if df[c].dtype == \"float64\"]\n",
    "#     int_cols = [c for c in df if df[c].dtype == \"int64\"]\n",
    "\n",
    "#     df[float_cols] = df[float_cols].astype(\"float32\")\n",
    "#     df[int_cols] = df[int_cols].astype(\"int32\")\n",
    "\n",
    "#     return df\n",
    "\n",
    "\n",
    "# # Loading CSV in chunks\n",
    "# chunksize = 10000  # Adjusting the chunk size based on your system's memory\n",
    "# chunk_list = []\n",
    "\n",
    "# for chunk in pd.read_csv(FILTERD_BOOKS, chunksize=chunksize):\n",
    "#     chunk = downcast_dtypes(chunk)\n",
    "#     chunk_list.append(chunk)\n",
    "\n",
    "# # books_df = pd.read_csv(FILTERD_BOOKS)\n",
    "# books_df = pd.concat(chunk_list, axis = 0)\n",
    "# # sim_martix = joblib.load(SIM_MATRIX)\n",
    "\n",
    "# # sim_matrix = np.random.rand(100000, 100)  # Example large matrix\n",
    "\n",
    "# # # Load large pickle file in a memory-efficient way\n",
    "# # sim_matrix = joblib.load(SIM_MATRIX, mmap_mode='r')\n",
    "# with pd.HDFStore('sim_martix.h5') as store:\n",
    "#     store.put('sim_matrix', pd.DataFrame(sim_matrix))\n",
    "\n",
    "# # Load large similarity matrix from HDF5\n",
    "# with pd.HDFStore('similarity_matrix_cb.h5') as store:\n",
    "#     if 'sim_matrix' in store:\n",
    "#         sim_matrix = store.get('sim_matrix').values\n",
    "#     else:\n",
    "#         raise KeyError(\"No object named 'sim_matrix' in the file\")\n",
    "\n",
    "# def get_top_n_books(n):\n",
    "#     '''\n",
    "#     This fun return books recommendation based on popularity\n",
    "#     '''\n",
    "#     df = books_df.sort_values(by=['Rating_count', 'Avg_rating'], ascending=False).head(n)\n",
    "#     return df\n",
    "\n",
    "# print(get_top_n_books( n = 20))\n",
    "\n",
    "\n",
    "# def recommendation_by_id(book_id): \n",
    "#     try: \n",
    "#         recomm_movies= pd.DataFrame(sim_martix[book_id].sort_values(ascending=True).head(10)).reset_index()[1:]\n",
    "#         recom_df = pd.DataFrame(columns=books_df.columns)\n",
    "#         for title in recomm_movies['Title']:\n",
    "#             recom =  books_df[books_df['Title'] == title] \n",
    "#             recom_df = pd.concat([recom_df , recom])\n",
    "#         return recom_df\n",
    "#     except KeyError:\n",
    "#         print('Book not found in the similarity matrix. Please choose another book.')\n",
    "\n",
    "# recommendation_by_id(6524312)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92d09289-8caf-4e02-ba79-32036fb07cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import requests\n",
    "\n",
    "# Define the paths\n",
    "FILTERD_BOOKS = r'C:\\Users\\gattu\\hybrid-book-recommendation-system\\models\\content base\\filtired_books_cb.pkl'\n",
    "SIM_MATRIX = r'C:\\Users\\gattu\\hybrid-book-recommendation-system\\data\\processed\\For content base\\similarity_matrix_cb.h5'\n",
    "\n",
    "# Downcast data types\n",
    "def downcast_dtypes(df):\n",
    "    float_cols = [c for c in df if df[c].dtype == \"float64\"]\n",
    "    int_cols = [c for c in df if df[c].dtype == \"int64\"]\n",
    "\n",
    "    df[float_cols] = df[float_cols].astype(\"float32\")\n",
    "    df[int_cols] = df[int_cols].astype(\"int32\")\n",
    "\n",
    "    return df\n",
    "\n",
    "# Loading CSV in chunks\n",
    "chunksize = 10000  # Adjusting the chunk size based on your system's memory\n",
    "chunk_list = []\n",
    "\n",
    "for chunk in pd.read_csv(FILTERD_BOOKS, chunksize=chunksize):\n",
    "    chunk = downcast_dtypes(chunk)\n",
    "    chunk_list.append(chunk)\n",
    "\n",
    "books_df = pd.concat(chunk_list, axis=0)\n",
    "\n",
    "# Save the similarity matrix to HDF5\n",
    "# Assuming you have the similarity matrix as a numpy array\n",
    "sim_matrix = np.random.rand(100000, 100)  # Example large matrix, replace with your actual data\n",
    "with pd.HDFStore(SIM_MATRIX) as store:\n",
    "    store.put('sim_matrix', pd.DataFrame(sim_matrix))\n",
    "\n",
    "# Load large similarity matrix from HDF5\n",
    "with pd.HDFStore(SIM_MATRIX) as store:\n",
    "    if 'sim_matrix' in store:\n",
    "        sim_matrix = store.get('sim_matrix').values\n",
    "    else:\n",
    "        raise KeyError(\"No object named 'sim_matrix' in the file\")\n",
    "\n",
    "# Function to get top N books\n",
    "def get_top_n_books(n):\n",
    "    '''\n",
    "    This function returns book recommendations based on popularity\n",
    "    '''\n",
    "    df = books_df.sort_values(by=['Rating_count', 'Avg_rating'], ascending=False).head(n)\n",
    "    return df\n",
    "\n",
    "# print(get_top_n_books(n=20))\n",
    "\n",
    "# Function to recommend books by ID\n",
    "def recommendation_by_id(book_id):\n",
    "    print('\\n\\nRecommendation by id\\n\\n')\n",
    "    try:\n",
    "        book_similarities = sim_matrix[book_id]\n",
    "        similar_indices = np.argsort(book_similarities)[1:11]  # Get top 10 most similar excluding itself\n",
    "        recom_df = books_df.iloc[similar_indices]\n",
    "        return recom_df\n",
    "    except KeyError:\n",
    "        print('Book not found in the similarity matrix. Please choose another book.')\n",
    "    except IndexError as e:\n",
    "        print(e)\n",
    "# print(recommendation_by_id(3676))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a03c97-b323-40c6-b954-7f67833f8880",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
